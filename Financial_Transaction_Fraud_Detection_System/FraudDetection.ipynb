{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edf17c0",
   "metadata": {},
   "source": [
    "# Fraud Detection\n",
    "\n",
    "This sample notebook demonstrates the usage of Fraud Detection.\n",
    "This solution is a superviser machine learning to predict whether a financial transaction is aFraud or not.\n",
    "\n",
    "\n",
    "\n",
    "This sample notebook shows you how to deploy Fraud detection using Amazon SageMaker.\n",
    "\n",
    "**Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to DefenSight Botnet Detector. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](# Subscribe-to-the-model-package)\n",
    "2. [Set up the environment](# Setup the environment)\n",
    "3. [Create the session](# Create the session)\n",
    "4. [Create Model](# Create model)\n",
    "5. [Create an endpoint and perform real-time inference](#-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "6. [Perform batch inference](# Perform-batch-inference)\n",
    "    1. [Configure the input S3 bucket folder](# A. -Configure the input S3 bucket folder)\n",
    "    2. [Deploy the model](# B. -Deploy the model)\n",
    "    3. [Download the file from output S3 bucket folder](# C. -Download the file from output S3 bucket folder)\n",
    "    4. [Visualize data](# D. -Visualize data)\n",
    "7. [Clean-up](# Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1914cf",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e45fee",
   "metadata": {},
   "source": [
    "# To subscribe to the model package:\n",
    "1. Open the model package listing page FraudDetection. \n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff83c7b",
   "metadata": {},
   "source": [
    "## 2. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5de63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefixes\n",
    "common_prefix = \"hdts-sagemaker-testing\"\n",
    "batch_inference_input_prefix = \"fraud-detection/input\"\n",
    "batch_inference_output_prefix = \"fraud-detection/output\"\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e813c2",
   "metadata": {},
   "source": [
    "## 3. Create the session\n",
    "\n",
    "The session remembers our connection parameters to Amazon SageMaker. We'll use it to perform all of our Amazon SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64648d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48e38a",
   "metadata": {},
   "source": [
    "## 4. Create Model\n",
    "\n",
    "Now we use the above Model Package to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d82fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = 'arn:aws:sagemaker:us-east-1:822940408628:model-package/FraudDetection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0c3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'FraudDetection'\n",
    "\n",
    "content_type = 'application/json'\n",
    "\n",
    "real_time_inference_instance_type = 'ml.t2.medium'\n",
    "batch_transform_inference_instance_type = 'ml.m5.large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afcd462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.Predictor(endpoint, session, content_type)\n",
    "\n",
    "# Create a deployable model from the model package\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls = predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fec78",
   "metadata": {},
   "source": [
    "## 5. Create-an-endpoint-and-perform-real-time-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90316a",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71d29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(1,real_time_inference_instance_type,endpoint_name = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b356df",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d51e7",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc474ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'input/test.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f665aed",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c25787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $model_name \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db52d7c",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e69e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "with open('output.txt', 'r') as f:\n",
    "    output = json.load(f)\n",
    "print(json.dumps(output,indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f29173",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28756788",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed78103",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2ef07",
   "metadata": {},
   "source": [
    "## 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981be02e",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771d621",
   "metadata": {},
   "source": [
    "### A. Configure the input S3 bucket folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efe7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_input_folder = 'input'\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder,common_prefix,batch_inference_input_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe6216",
   "metadata": {},
   "source": [
    "### B. Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db78f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: FraudDetection-2023-10-12-07-34-58-977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [10] [INFO] Starting gunicorn 21.2.0\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Oct/2023:07:39:47 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Oct/2023:07:39:47 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Oct/2023:07:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Oct/2023:07:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2023-10-12T07:39:47.201:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [10] [INFO] Starting gunicorn 21.2.0\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2023-10-12 07:39:39 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[35mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[35m[2023-10-12 07:39:39 +0000] [10] [INFO] Starting gunicorn 21.2.0\u001b[0m\n",
      "\u001b[35m[2023-10-12 07:39:39 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[35m[2023-10-12 07:39:39 +0000] [10] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2023-10-12 07:39:39 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[35m[2023-10-12 07:39:39 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Oct/2023:07:39:47 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Oct/2023:07:39:47 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Oct/2023:07:39:47 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Oct/2023:07:39:47 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Oct/2023:07:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Oct/2023:07:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2023-10-12T07:39:47.201:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(1,batch_transform_inference_instance_type,output_path=\"s3://\"+common_prefix+\"/\"+batch_inference_output_prefix+\"/\")\n",
    "transformer.transform(transform_input,content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0b5d3",
   "metadata": {},
   "source": [
    "### C. Download the file from output S3 bucket folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d478d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "with open('output2.txt','wb') as f:\n",
    "    s3_conn.download_fileobj(common_prefix,batch_inference_output_prefix+'/'+'test.json.out',f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec69c8",
   "metadata": {},
   "source": [
    "### D. Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f7ab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "with open('output2.txt','r') as f:\n",
    "    output=json.load(f)\n",
    "print(json.dumps(output,indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab25c6",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9037a82",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a31e41ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: FraudDetection-2023-10-12-07-34-58-131\n"
     ]
    }
   ],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f07ec",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28271df2",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665acda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78ce60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
